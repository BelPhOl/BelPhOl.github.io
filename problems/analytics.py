#!/usr/bin/env python3
"""
Analytics script for Belarus Physics Olympiad Problem Bank
Analyzes problem metadata to provide insights about tags, methods, skills, and trends.
"""

import json
import pandas as pd
import numpy as np
from collections import Counter, defaultdict
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import argparse
import sys

class ProblemAnalytics:
    def __init__(self, json_file='pdf_metadata.json'):
        """Initialize the analytics with problem data."""
        self.json_file = json_file
        self.problems = []
        self.df = None
        self.load_data()
    
    def load_data(self):
        """Load problem data from JSON file."""
        try:
            with open(self.json_file, 'r', encoding='utf-8') as f:
                self.problems = json.load(f)
            print(f"‚úÖ Loaded {len(self.problems)} problems from {self.json_file}")
            self.create_dataframe()
        except FileNotFoundError:
            print(f"‚ùå Error: {self.json_file} not found")
            sys.exit(1)
        except json.JSONDecodeError as e:
            print(f"‚ùå Error parsing JSON: {e}")
            sys.exit(1)
    
    def create_dataframe(self):
        """Create pandas DataFrame from problem data."""
        # Flatten the data for easier analysis
        flat_data = []
        for problem in self.problems:
            flat_data.append({
                'id': problem['id'],
                'year': problem['year'],
                'stage': problem['stage'],
                'grade': problem['grade'],
                'number': problem['number'],
                'title': problem['title'],
                'difficulty': problem['difficulty'],
                'target': problem['target'],
                'tags_count': len(problem['tags']),
                'skills_count': len(problem['skills']),
                'methods_count': len(problem['methods']),
                'tags': problem['tags'],
                'skills': problem['skills'],
                'methods': problem['methods']
            })
        
        self.df = pd.DataFrame(flat_data)
        print(f"üìä Created DataFrame with {len(self.df)} rows and {len(self.df.columns)} columns")
    
    def get_basic_stats(self):
        """Get basic statistics about the problems."""
        print("\n" + "="*50)
        print("üìà –û–°–ù–û–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("="*50)
        
        print(f"üìö –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {len(self.problems)}")
        print(f"üìÖ –ì–æ–¥—ã: {self.df['year'].min()} - {self.df['year'].max()}")
        print(f"üéì –ö–ª–∞—Å—Å—ã: {sorted(self.df['grade'].unique())}")
        print(f"üèÜ –≠—Ç–∞–ø—ã: {sorted(self.df['stage'].unique())}")
        print(f"‚ö° –£—Ä–æ–≤–Ω–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: {sorted(self.df['difficulty'].unique())}")
        
        # Year distribution
        print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º:")
        year_counts = self.df['year'].value_counts().sort_index()
        for year, count in year_counts.items():
            print(f"  {year}: {count} –∑–∞–¥–∞—á")
        
        # Grade distribution  
        print(f"\nüéì –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
        grade_counts = self.df['grade'].value_counts().sort_index()
        for grade, count in grade_counts.items():
            print(f"  {grade} –∫–ª–∞—Å—Å: {count} –∑–∞–¥–∞—á")
            
        # Difficulty distribution
        print(f"\n‚ö° –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:")
        difficulty_counts = self.df['difficulty'].value_counts()
        difficulty_labels = {
            'basic': '–ë–∞–∑–æ–≤—ã–π',
            'intermediate': '–°—Ä–µ–¥–Ω–∏–π', 
            'advanced': '–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π',
            'very_advanced': '–û—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã–π',
            'mixed': '–°–º–µ—à–∞–Ω–Ω—ã–π'
        }
        for difficulty, count in difficulty_counts.items():
            label = difficulty_labels.get(difficulty, difficulty)
            print(f"  {label}: {count} –∑–∞–¥–∞—á")
    
    def analyze_tags(self, top_n=20):
        """Analyze the most frequent tags."""
        print("\n" + "="*50)
        print("üè∑Ô∏è  –ê–ù–ê–õ–ò–ó –¢–ï–ì–û–í")
        print("="*50)
        
        # Count all tags
        all_tags = []
        for problem in self.problems:
            all_tags.extend(problem['tags'])
        
        tag_counts = Counter(all_tags)
        print(f"üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–≥–æ–≤: {len(tag_counts)}")
        print(f"üî• –¢–æ–ø-{top_n} —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–≥–æ–≤:")
        
        for i, (tag, count) in enumerate(tag_counts.most_common(top_n), 1):
            percentage = (count / len(self.problems)) * 100
            print(f"  {i:2d}. {tag:<30} {count:3d} ({percentage:.1f}%)")
        
        return tag_counts
    
    def analyze_skills(self, top_n=15):
        """Analyze the most frequent skills."""
        print("\n" + "="*50)
        print("üéØ –ê–ù–ê–õ–ò–ó –ù–ê–í–´–ö–û–í")
        print("="*50)
        
        # Count all skills
        all_skills = []
        for problem in self.problems:
            all_skills.extend(problem['skills'])
        
        skill_counts = Counter(all_skills)
        print(f"üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤: {len(skill_counts)}")
        print(f"üî• –¢–æ–ø-{top_n} —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤:")
        
        for i, (skill, count) in enumerate(skill_counts.most_common(top_n), 1):
            percentage = (count / len(self.problems)) * 100
            print(f"  {i:2d}. {skill:<50} {count:3d} ({percentage:.1f}%)")
        
        return skill_counts
    
    def analyze_methods(self, top_n=15):
        """Analyze the most frequent methods."""
        print("\n" + "="*50)
        print("‚öôÔ∏è  –ê–ù–ê–õ–ò–ó –ú–ï–¢–û–î–û–í")
        print("="*50)
        
        # Count all methods
        all_methods = []
        for problem in self.problems:
            all_methods.extend(problem['methods'])
        
        method_counts = Counter(all_methods)
        print(f"üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤: {len(method_counts)}")
        print(f"üî• –¢–æ–ø-{top_n} —Å–∞–º—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –º–µ—Ç–æ–¥–æ–≤:")
        
        for i, (method, count) in enumerate(method_counts.most_common(top_n), 1):
            percentage = (count / len(self.problems)) * 100
            print(f"  {i:2d}. {method:<50} {count:3d} ({percentage:.1f}%)")
        
        return method_counts
    
    def analyze_by_difficulty(self):
        """Analyze problems by difficulty level."""
        print("\n" + "="*50)
        print("üìä –ê–ù–ê–õ–ò–ó –ü–û –°–õ–û–ñ–ù–û–°–¢–ò")
        print("="*50)
        
        for difficulty in sorted(self.df['difficulty'].unique()):
            difficulty_problems = [p for p in self.problems if p['difficulty'] == difficulty]
            
            difficulty_labels = {
                'basic': '–ë–∞–∑–æ–≤—ã–π',
                'intermediate': '–°—Ä–µ–¥–Ω–∏–π',
                'advanced': '–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π', 
                'very_advanced': '–û—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã–π',
                'mixed': '–°–º–µ—à–∞–Ω–Ω—ã–π'
            }
            
            label = difficulty_labels.get(difficulty, difficulty)
            print(f"\nüéØ {label.upper()} ({len(difficulty_problems)} –∑–∞–¥–∞—á)")
            
            # Most common tags for this difficulty
            tags = []
            for problem in difficulty_problems:
                tags.extend(problem['tags'])
            
            tag_counts = Counter(tags)
            print(f"  –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–≥–∏:")
            for tag, count in tag_counts.most_common(5):
                print(f"    ‚Ä¢ {tag} ({count})")
    
    def analyze_trends(self):
        """Analyze trends over years."""
        print("\n" + "="*50)
        print("üìà –ê–ù–ê–õ–ò–ó –¢–†–ï–ù–î–û–í")
        print("="*50)
        
        # Problems per year
        year_stats = defaultdict(lambda: {'total': 0, 'grades': defaultdict(int), 'difficulties': defaultdict(int)})
        
        for problem in self.problems:
            year = problem['year']
            year_stats[year]['total'] += 1
            year_stats[year]['grades'][problem['grade']] += 1
            year_stats[year]['difficulties'][problem['difficulty']] += 1
        
        print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥–æ–¥–∞–º:")
        for year in sorted(year_stats.keys(), reverse=True):
            stats = year_stats[year]
            print(f"\n  {year}: {stats['total']} –∑–∞–¥–∞—á")
            
            # Grade distribution
            grades = sorted(stats['grades'].items())
            grade_str = ", ".join([f"{g} –∫–ª: {c}" for g, c in grades])
            print(f"    –ö–ª–∞—Å—Å—ã: {grade_str}")
            
            # Most common difficulty
            top_difficulty = max(stats['difficulties'].items(), key=lambda x: x[1])
            print(f"    –û—Å–Ω–æ–≤–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {top_difficulty[0]} ({top_difficulty[1]} –∑–∞–¥–∞—á)")
    
    def get_recommendations(self):
        """Get recommendations for website optimization."""
        print("\n" + "="*50)
        print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –°–ê–ô–¢–ê")
        print("="*50)
        
        # Analyze tag distribution
        all_tags = []
        for problem in self.problems:
            all_tags.extend(problem['tags'])
        tag_counts = Counter(all_tags)
        
        print("üéØ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Ç–µ–≥–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:")
        priority_tags = tag_counts.most_common(15)
        for i, (tag, count) in enumerate(priority_tags, 1):
            print(f"  {i:2d}. {tag}")
        
        print("\nüîç –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–æ–∏—Å–∫—É:")
        print("  ‚Ä¢ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –ø–æ —Ç–µ–≥–∞–º:", ', '.join([tag for tag, _ in priority_tags[:10]]))
        print("  ‚Ä¢ –î–æ–±–∞–≤–∏—Ç—å –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–≥–æ–≤")
        print("  ‚Ä¢ –°–æ–∑–¥–∞—Ç—å –±—ã—Å—Ç—Ä—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è —Ç–æ–ø-5 —Ç–µ–≥–æ–≤")
        
        # Difficulty balance
        difficulty_dist = self.df['difficulty'].value_counts()
        print(f"\n‚öñÔ∏è  –ë–∞–ª–∞–Ω—Å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:")
        print(f"  ‚Ä¢ –ë–∞–∑–æ–≤—ã—Ö: {difficulty_dist.get('basic', 0)}")
        print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–∏—Ö: {difficulty_dist.get('intermediate', 0)}")
        print(f"  ‚Ä¢ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö: {difficulty_dist.get('advanced', 0)}")
        print(f"  ‚Ä¢ –û—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã—Ö: {difficulty_dist.get('very_advanced', 0)}")
        
        # Recommendations
        print(f"\nüìö –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É:")
        if difficulty_dist.get('basic', 0) < 10:
            print("  ‚Ä¢ –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –±–∞–∑–æ–≤—ã—Ö –∑–∞–¥–∞—á –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö")
        if difficulty_dist.get('very_advanced', 0) > 20:
            print("  ‚Ä¢ –°–æ–∑–¥–∞—Ç—å —Ä–∞–∑–¥–µ–ª –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤")
        
        # Year coverage
        year_range = self.df['year'].max() - self.df['year'].min()
        print(f"\nüìÖ –í—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ: {year_range + 1} –ª–µ—Ç")
        if year_range > 10:
            print("  ‚Ä¢ –î–æ–±–∞–≤–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–µ—Å—è—Ç–∏–ª–µ—Ç–∏—è–º")
            print("  ‚Ä¢ –°–æ–∑–¥–∞—Ç—å —Ä–∞–∑–¥–µ–ª '–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏'")
    
    def export_data(self, format='json'):
        """Export analyzed data."""
        print("\n" + "="*50)
        print("üíæ –≠–ö–°–ü–û–†–¢ –î–ê–ù–ù–´–•")
        print("="*50)
        
        # Get all analytics data
        all_tags = []
        all_skills = []
        all_methods = []
        
        for problem in self.problems:
            all_tags.extend(problem['tags'])
            all_skills.extend(problem['skills'])
            all_methods.extend(problem['methods'])
        
        analytics_data = {
            'summary': {
                'total_problems': len(self.problems),
                'years_covered': list(sorted(self.df['year'].unique())),
                'grades': list(sorted(self.df['grade'].unique())),
                'stages': list(sorted(self.df['stage'].unique())),
                'difficulties': list(sorted(self.df['difficulty'].unique()))
            },
            'tags': {
                'total_unique': len(set(all_tags)),
                'most_common': dict(Counter(all_tags).most_common(20))
            },
            'skills': {
                'total_unique': len(set(all_skills)),
                'most_common': dict(Counter(all_skills).most_common(15))
            },
            'methods': {
                'total_unique': len(set(all_methods)),
                'most_common': dict(Counter(all_methods).most_common(15))
            },
            'distributions': {
                'by_year': dict(self.df['year'].value_counts().sort_index()),
                'by_grade': dict(self.df['grade'].value_counts().sort_index()),
                'by_difficulty': dict(self.df['difficulty'].value_counts())
            }
        }
        
        # Export to JSON
        if format in ['json', 'all']:
            with open('analytics_report.json', 'w', encoding='utf-8') as f:
                json.dump(analytics_data, f, ensure_ascii=False, indent=2)
            print("üìÑ Exported to analytics_report.json")
        
        # Export to CSV
        if format in ['csv', 'all']:
            self.df.to_csv('problems_data.csv', index=False, encoding='utf-8')
            print("üìä Exported to problems_data.csv")
        
        return analytics_data
    
    def run_full_analysis(self):
        """Run complete analysis."""
        print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –ë–ê–ù–ö–ê –ó–ê–î–ê–ß BelPhO")
        print("="*60)
        
        self.get_basic_stats()
        tag_counts = self.analyze_tags()
        skill_counts = self.analyze_skills()
        method_counts = self.analyze_methods()
        self.analyze_by_difficulty()
        self.analyze_trends()
        self.get_recommendations()
        
        # Export data
        analytics_data = self.export_data('all')
        
        print("\n" + "="*60)
        print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
        print("="*60)
        print("üìä –°–æ–∑–¥–∞–Ω –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∞–π—Ç–∞")
        print("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞")
        
        return analytics_data

def main():
    """Main function to run analytics."""
    parser = argparse.ArgumentParser(description='Analyze Belarus Physics Olympiad problems')
    parser.add_argument('--file', '-f', default='pdf_metadata.json', 
                       help='Path to JSON file with problem metadata')
    parser.add_argument('--export', '-e', choices=['json', 'csv', 'all'], 
                       default='all', help='Export format')
    parser.add_argument('--tags', '-t', type=int, default=20,
                       help='Number of top tags to show')
    parser.add_argument('--skills', '-s', type=int, default=15,
                       help='Number of top skills to show')
    parser.add_argument('--methods', '-m', type=int, default=15,
                       help='Number of top methods to show')
    
    args = parser.parse_args()
    
    # Run analysis
    analytics = ProblemAnalytics(args.file)
    analytics.run_full_analysis()

if __name__ == "__main__":
    main() 